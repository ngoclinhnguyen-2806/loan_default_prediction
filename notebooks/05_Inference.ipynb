{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "123d13d2-9902-4e7f-a709-fe17313da18e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "from datetime import datetime, timedelta\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import pprint\n",
    "import pyspark\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql.types import StringType, IntegerType, FloatType, DateType\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import make_scorer, f1_score, roc_auc_score\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import mlflow\n",
    "import mlflow.xgboost\n",
    "from mlflow.tracking import MlflowClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e15d6ecd-9034-43e1-8848-22f70262ae3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fccf483d-91bd-4b1a-a6ab-1619c2274a5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/11/10 17:06:35 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "# Initialize SparkSession\n",
    "spark = pyspark.sql.SparkSession.builder \\\n",
    "    .appName(\"BuildInference\") \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .config(\"spark.driver.memory\", \"8g\") \\\n",
    "    .config(\"spark.executor.memory\", \"8g\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Set log level to ERROR to hide warnings\n",
    "spark.sparkContext.setLogLevel(\"ERROR\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "121ec355-5fb2-4645-af05-8610d1ca9763",
   "metadata": {},
   "source": [
    "## Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6a4a51f9-8859-41b4-9ae3-3e7b9b9ea199",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(model_name=\"credit_model_LR_3\", snapshot_date_str=\"2024-08-01\", fallback_dir=\"/app/airflow/model_bank/\"):\n",
    "    \"\"\"\n",
    "    Load model from MLflow Registry or fallback to pickle file.\n",
    "    \n",
    "    Args:\n",
    "        model_name: Name of the model in MLflow Registry\n",
    "        snapshot_date: Snapshot date string (e.g., \"2024-08-01\") for pickle fallback\n",
    "        fallback_dir: Directory containing pickle files\n",
    "    \n",
    "    Returns:\n",
    "        Loaded model object\n",
    "    \"\"\"\n",
    "    snapshot_date = snapshot_date_str.replace(\"-\", \"_\")\n",
    "    \n",
    "    # Try loading from MLflow Registry\n",
    "    try:\n",
    "        mlflow.set_tracking_uri(\"http://mlflow:5000\")\n",
    "        print(f\"üîç Attempting to load model from MLflow Registry: {model_name}\")\n",
    "        \n",
    "        model = mlflow.sklearn.load_model(f\"models:/{model_name}/latest\")\n",
    "        print(f\"‚úÖ Successfully loaded model from MLflow Registry\")\n",
    "        \n",
    "        # Try to load scaler artifact if needed\n",
    "        try:\n",
    "            client = MlflowClient()\n",
    "            versions = client.search_model_versions(f\"name='{model_name}'\")\n",
    "            if versions:\n",
    "                latest_version = versions[0]\n",
    "                run_id = latest_version.run_id\n",
    "                scaler_path = mlflow.artifacts.download_artifacts(\n",
    "                    run_id=run_id, \n",
    "                    artifact_path=\"preprocessing/temp_scaler.pkl\"\n",
    "                )\n",
    "                with open(scaler_path, 'rb') as f:\n",
    "                    scaler = pickle.load(f)\n",
    "                print(f\"‚úÖ Successfully loaded scaler from MLflow\")\n",
    "                return model, scaler\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è  Could not load scaler from MLflow: {e}\")\n",
    "            return model, None\n",
    "            \n",
    "        return model, None\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Failed to load from MLflow Registry: {e}\")\n",
    "        \n",
    "        # Fallback to pickle file\n",
    "        pickle_filename = f\"credit_model_LR_{snapshot_date}.pkl\"\n",
    "        pickle_path = f\"{fallback_dir}{pickle_filename}\"\n",
    "        \n",
    "        try:\n",
    "            print(f\"üîç Attempting to load from pickle: {pickle_path}\")\n",
    "            with open(pickle_path, 'rb') as f:\n",
    "                model_data = pickle.load(f)\n",
    "            \n",
    "            # Handle different pickle formats\n",
    "            if isinstance(model_data, dict):\n",
    "                model = model_data.get('model')\n",
    "                scaler = model_data.get('scaler')\n",
    "                print(f\"‚úÖ Successfully loaded model and scaler from pickle (dict format)\")\n",
    "            elif isinstance(model_data, tuple):\n",
    "                model, scaler = model_data\n",
    "                print(f\"‚úÖ Successfully loaded model and scaler from pickle (tuple format)\")\n",
    "            else:\n",
    "                model = model_data\n",
    "                scaler = None\n",
    "                print(f\"‚úÖ Successfully loaded model from pickle (single object)\")\n",
    "            \n",
    "            return model, scaler\n",
    "            \n",
    "        except FileNotFoundError:\n",
    "            print(f\"‚ùå Pickle file not found: {pickle_path}\")\n",
    "            raise Exception(f\"Could not load model from MLflow or pickle file: {pickle_path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Failed to load from pickle: {e}\")\n",
    "            raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9bf41e15-e189-4505-be87-8a40b6ff0c3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Attempting to load model from MLflow Registry: credit_model_LR_3\n",
      "‚ùå Failed to load from MLflow Registry: No such file or directory: '/mlflow/mlruns/6/models/m-300e00dc120a402cbc245d53cd9d574b/artifacts/.'\n",
      "üîç Attempting to load from pickle: /app/airflow/model_bank/credit_model_LR_2024_08_01.pkl\n",
      "‚úÖ Successfully loaded model and scaler from pickle (dict format)\n",
      "\n",
      "Model type: LogisticRegression\n",
      "\n",
      "‚úÖ Test prediction: [0]\n"
     ]
    }
   ],
   "source": [
    "# Usage example:\n",
    "if __name__ == \"__main__\":\n",
    "    # Try to load model\n",
    "    model, scaler = load_model(\n",
    "        model_name=\"credit_model_LR_3\",\n",
    "        snapshot_date_str=\"2024-08-01\",\n",
    "        fallback_dir=\"/app/airflow/model_bank/\"\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nModel type: {type(model).__name__}\")\n",
    "    if scaler:\n",
    "        print(f\"Scaler type: {type(scaler).__name__}\")\n",
    "    \n",
    "    # Test prediction if model loaded successfully\n",
    "    if model:\n",
    "        import numpy as np\n",
    "        n_features = model.n_features_in_ if hasattr(model, 'n_features_in_') else 10\n",
    "        dummy_data = np.random.rand(1, n_features)\n",
    "        \n",
    "        if scaler:\n",
    "            dummy_data = scaler.transform(dummy_data)\n",
    "        \n",
    "        prediction = model.predict(dummy_data)\n",
    "        print(f\"\\n‚úÖ Test prediction: {prediction}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf1c2b7d-ec02-4dca-9bdf-14c10da46cec",
   "metadata": {},
   "source": [
    "## LOAD DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9ca2a21c-0936-4c82-8124-3cc3a74e5960",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- set up config ---\n",
    "config = {}\n",
    "config[\"model_name\"] = \"LR\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b03f12bd-ec4f-4a6c-8c92-0c2e12fa0356",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row_count: 12500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------------+-------------+----------------+------------------+-----------+----------------------+-------------------+-------------------------------------------------+------------------------------------------------+-------------------------------------------------+------------------------------------------------+--------------------------------------------------+-------------------------------------------------+-------------------+---------------+--------------+----------------------+--------------------------------+--------------------------+-----------------------------+--------------------------+-------------------------+------------------------------------+------------------------+-------------+----------------+--------------+--------------+--------------+--------------+-----------+------------+------------+------------+------------+------------+------------+------------+------------+------------+-------------+-------------+-------------+-------------+-------------+-------------+-------------+-------------+-------------+-------------+-------------+----+----+----+----+----+----+----+----+----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-------------+\n",
      "|Customer_ID|application_date|Annual_Income|Outstanding_Debt|Credit_History_Age|Num_of_Loan|Num_of_Delayed_Payment|Delay_from_due_date|Payment_Behaviour_High_spent_Small_value_payments|Payment_Behaviour_Low_spent_Large_value_payments|Payment_Behaviour_Low_spent_Medium_value_payments|Payment_Behaviour_Low_spent_Small_value_payments|Payment_Behaviour_High_spent_Medium_value_payments|Payment_Behaviour_High_spent_Large_value_payments|Credit_Mix_Standard|Credit_Mix_Good|Credit_Mix_Bad|Type_of_Loan_Auto_Loan|Type_of_Loan_Credit_Builder_Loan|Type_of_Loan_Personal_Loan|Type_of_Loan_Home_Equity_Loan|Type_of_Loan_Mortgage_Loan|Type_of_Loan_Student_Loan|Type_of_Loan_Debt_Consolidation_Loan|Type_of_Loan_Payday_Loan|is_occu_known|age_band_Unknown|age_band_18_24|age_band_25_34|age_band_35_44|age_band_45_54|age_band_55|fe_1_sum_all|fe_2_sum_all|fe_3_sum_all|fe_4_sum_all|fe_5_sum_all|fe_6_sum_all|fe_7_sum_all|fe_8_sum_all|fe_9_sum_all|fe_10_sum_all|fe_11_sum_all|fe_12_sum_all|fe_13_sum_all|fe_14_sum_all|fe_15_sum_all|fe_16_sum_all|fe_17_sum_all|fe_18_sum_all|fe_19_sum_all|fe_20_sum_all|fe_1|fe_2|fe_3|fe_4|fe_5|fe_6|fe_7|fe_8|fe_9|fe_10|fe_11|fe_12|fe_13|fe_14|fe_15|fe_16|fe_17|fe_18|fe_19|fe_20|snapshot_date|\n",
      "+-----------+----------------+-------------+----------------+------------------+-----------+----------------------+-------------------+-------------------------------------------------+------------------------------------------------+-------------------------------------------------+------------------------------------------------+--------------------------------------------------+-------------------------------------------------+-------------------+---------------+--------------+----------------------+--------------------------------+--------------------------+-----------------------------+--------------------------+-------------------------+------------------------------------+------------------------+-------------+----------------+--------------+--------------+--------------+--------------+-----------+------------+------------+------------+------------+------------+------------+------------+------------+------------+-------------+-------------+-------------+-------------+-------------+-------------+-------------+-------------+-------------+-------------+-------------+----+----+----+----+----+----+----+----+----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-------------+\n",
      "| CUS_0x1048|      2024-02-01|     42387.54|         1835.67|             120.0|          7|                     8|                  9|                                                1|                                               0|                                                0|                                               0|                                                 0|                                                0|                  1|              0|             0|                     0|                               0|                         1|                            1|                         0|                        0|                                   1|                       1|            1|               0|             0|             1|             0|             0|          0|        1583|        1553|        1911|        1324|        1663|        1518|         946|        1244|        1949|         1075|         1443|         1724|         1624|         1148|         1224|         1416|         1080|         1475|         1264|         1558| 264| 137| 178| 279| 142| 222|  29| 131|  67|   97|  143|  353|  211|  156| -139|  254|   40|   28|  151|  -95|   2024-02-01|\n",
      "+-----------+----------------+-------------+----------------+------------------+-----------+----------------------+-------------------+-------------------------------------------------+------------------------------------------------+-------------------------------------------------+------------------------------------------------+--------------------------------------------------+-------------------------------------------------+-------------------+---------------+--------------+----------------------+--------------------------------+--------------------------+-----------------------------+--------------------------+-------------------------+------------------------------------+------------------------+-------------+----------------+--------------+--------------+--------------+--------------+-----------+------------+------------+------------+------------+------------+------------+------------+------------+------------+-------------+-------------+-------------+-------------+-------------+-------------+-------------+-------------+-------------+-------------+-------------+----+----+----+----+----+----+----+----+----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# --- load feature store ---\n",
    "FEATURE_DIR = \"/app/datamart/gold/feature_store\"\n",
    "features_store_sdf = spark.read.parquet(FEATURE_DIR)\n",
    "print(\"row_count:\",features_store_sdf.count())\n",
    "\n",
    "features_store_sdf.show(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "860cfd90-5085-40f6-ba2e-1f1bb0147b70",
   "metadata": {},
   "source": [
    "### LOOP THROUGH ALL DAYS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d63f40e4-d18a-4bec-b7ec-083a3f944dfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extracted features_sdf 493 2024-09-01 00:00:00\n",
      "‚ö†Ô∏è  No scaler found, using raw\n",
      "/app/datamart/gold/model_predictions/LR/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/site-packages/sklearn/utils/validation.py:2732: UserWarning: X has feature names, but LogisticRegression was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extracted features_sdf 456 2024-10-01 00:00:00\n",
      "‚ö†Ô∏è  No scaler found, using raw\n",
      "/app/datamart/gold/model_predictions/LR/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/site-packages/sklearn/utils/validation.py:2732: UserWarning: X has feature names, but LogisticRegression was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extracted features_sdf 488 2024-11-01 00:00:00\n",
      "‚ö†Ô∏è  No scaler found, using raw\n",
      "/app/datamart/gold/model_predictions/LR/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/site-packages/sklearn/utils/validation.py:2732: UserWarning: X has feature names, but LogisticRegression was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extracted features_sdf 515 2024-12-01 00:00:00\n",
      "‚ö†Ô∏è  No scaler found, using raw\n",
      "/app/datamart/gold/model_predictions/LR/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/site-packages/sklearn/utils/validation.py:2732: UserWarning: X has feature names, but LogisticRegression was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extracted features_sdf 526 2025-01-01 00:00:00\n",
      "‚ö†Ô∏è  No scaler found, using raw\n",
      "/app/datamart/gold/model_predictions/LR/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/site-packages/sklearn/utils/validation.py:2732: UserWarning: X has feature names, but LogisticRegression was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "for snapshot_date in ['2024-09-01', '2024-10-01', '2024-11-01', '2024-12-01', '2025-01-01']:\n",
    "    \n",
    "    config[\"snapshot_date_str\"] = snapshot_date\n",
    "    config[\"snapshot_date\"] = datetime.strptime(config[\"snapshot_date_str\"], \"%Y-%m-%d\")\n",
    "    \n",
    "    try:\n",
    "        features_sdf = features_store_sdf.filter((col(\"snapshot_date\") == config[\"snapshot_date\"]))\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Using application_date instead of snapshot_date due to: {e}\")\n",
    "        features_sdf = features_store_sdf.filter((col(\"application_date\") == config[\"snapshot_date\"]))\n",
    "    \n",
    "    print(\"extracted features_sdf\", features_sdf.count(), config[\"snapshot_date\"])\n",
    "    \n",
    "    features_pdf = features_sdf.toPandas()\n",
    "    \n",
    "    #---------------------------------------------------\n",
    "    # PREPROCESS DATA\n",
    "    #---------------------------------------------------\n",
    "    \n",
    "    # prepare X_inference\n",
    "    feature_cols = [fe_col for fe_col in features_pdf.columns if fe_col not in ['Customer_ID', 'application_date', 'snapshot_date']]\n",
    "    X_features = features_pdf[feature_cols]\n",
    "    \n",
    "    X_features.head()\n",
    "    \n",
    "    # Apply scaler if it exists\n",
    "    if scaler is not None:\n",
    "        print(\"üîÑ Applying scaler transformation...\")\n",
    "        X_scaled = scaler.transform(X_features)\n",
    "        print(f\"‚úÖ Features scaled: {X_features.shape} -> {X_scaled.shape}\")\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è  No scaler found, using raw\")\n",
    "        # --- Scaling ---\n",
    "        X_scaled = X_features\n",
    "    \n",
    "    #---------------------------------------------------\n",
    "    # MAKE INFERENCE & PREPARE OUTPUT\n",
    "    #---------------------------------------------------\n",
    "    \n",
    "    y_inference = model.predict_proba(X_scaled)[:, 1]\n",
    "    y_inference\n",
    "    \n",
    "    # prepare output\n",
    "    y_inference_pdf = features_pdf[[\"Customer_ID\",\"snapshot_date\"]].copy()\n",
    "    y_inference_pdf[\"model_name\"] = config[\"model_name\"]\n",
    "    y_inference_pdf[\"model_predictions\"] = y_inference\n",
    "    \n",
    "    #---------------------------------------------------\n",
    "    # SAVE TO GOLD LAYER\n",
    "    #---------------------------------------------------\n",
    "    \n",
    "    # create gold datalake\n",
    "    snapshot_date_path = config[\"snapshot_date_str\"].replace('-','_')\n",
    "    prediction_directory = f\"/app/datamart/gold/model_predictions/{config[\"model_name\"]}/\"\n",
    "    print(prediction_directory)\n",
    "    \n",
    "    if not os.path.exists(prediction_directory):\n",
    "        os.makedirs(prediction_directory)\n",
    "    \n",
    "    filepath = os.path.join(prediction_directory, f\"predictions_{snapshot_date_path}.csv\")\n",
    "    y_inference_pdf.to_csv(filepath, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ccad90c-9572-440d-b28a-d091ccf253f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fbc9d3fd-84b6-4230-87f8-d4fa3f48aa97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "---completed job---\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.stop()\n",
    "\n",
    "print('\\n\\n---completed job---\\n\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54602125-dead-48cb-9d73-db060f419401",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7be7345-42a0-46c3-8b70-174d1d170f04",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5487454d-f3d8-44e6-be3b-5ab8be31e466",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "70d877d8-7e4a-43ce-af0f-d03ddb2429e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extracted features_sdf 493 2024-09-01 00:00:00\n"
     ]
    }
   ],
   "source": [
    "# extract feature store\n",
    "try:\n",
    "    features_sdf = features_store_sdf.filter((col(\"snapshot_date\") == config[\"snapshot_date\"]))\n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è Using application_date instead of snapshot_date due to: {e}\")\n",
    "    features_sdf = features_store_sdf.filter((col(\"application_date\") == config[\"snapshot_date\"]))\n",
    "\n",
    "print(\"extracted features_sdf\", features_sdf.count(), config[\"snapshot_date\"])\n",
    "\n",
    "features_pdf = features_sdf.toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1597e40-237f-4568-9fcd-39f51e9b6a60",
   "metadata": {},
   "source": [
    "## PREPROCESS DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "28b12d0f-79ca-41f8-9c78-bc2134bf5ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- preprocess data for modeling ---\n",
    "# prepare X_inference\n",
    "feature_cols = [fe_col for fe_col in features_pdf.columns if fe_col not in ['Customer_ID', 'application_date', 'snapshot_date']]\n",
    "X_features = features_pdf[feature_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f4488f64-9775-4b9e-83fe-bcd66c16a2e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Annual_Income</th>\n",
       "      <th>Outstanding_Debt</th>\n",
       "      <th>Credit_History_Age</th>\n",
       "      <th>Num_of_Loan</th>\n",
       "      <th>Num_of_Delayed_Payment</th>\n",
       "      <th>Delay_from_due_date</th>\n",
       "      <th>Payment_Behaviour_High_spent_Small_value_payments</th>\n",
       "      <th>Payment_Behaviour_Low_spent_Large_value_payments</th>\n",
       "      <th>Payment_Behaviour_Low_spent_Medium_value_payments</th>\n",
       "      <th>Payment_Behaviour_Low_spent_Small_value_payments</th>\n",
       "      <th>Payment_Behaviour_High_spent_Medium_value_payments</th>\n",
       "      <th>Payment_Behaviour_High_spent_Large_value_payments</th>\n",
       "      <th>Credit_Mix_Standard</th>\n",
       "      <th>Credit_Mix_Good</th>\n",
       "      <th>Credit_Mix_Bad</th>\n",
       "      <th>Type_of_Loan_Auto_Loan</th>\n",
       "      <th>Type_of_Loan_Credit_Builder_Loan</th>\n",
       "      <th>Type_of_Loan_Personal_Loan</th>\n",
       "      <th>Type_of_Loan_Home_Equity_Loan</th>\n",
       "      <th>Type_of_Loan_Mortgage_Loan</th>\n",
       "      <th>Type_of_Loan_Student_Loan</th>\n",
       "      <th>Type_of_Loan_Debt_Consolidation_Loan</th>\n",
       "      <th>Type_of_Loan_Payday_Loan</th>\n",
       "      <th>is_occu_known</th>\n",
       "      <th>age_band_Unknown</th>\n",
       "      <th>age_band_18_24</th>\n",
       "      <th>age_band_25_34</th>\n",
       "      <th>age_band_35_44</th>\n",
       "      <th>age_band_45_54</th>\n",
       "      <th>age_band_55</th>\n",
       "      <th>fe_1_sum_all</th>\n",
       "      <th>fe_2_sum_all</th>\n",
       "      <th>fe_3_sum_all</th>\n",
       "      <th>fe_4_sum_all</th>\n",
       "      <th>fe_5_sum_all</th>\n",
       "      <th>fe_6_sum_all</th>\n",
       "      <th>fe_7_sum_all</th>\n",
       "      <th>fe_8_sum_all</th>\n",
       "      <th>fe_9_sum_all</th>\n",
       "      <th>fe_10_sum_all</th>\n",
       "      <th>fe_11_sum_all</th>\n",
       "      <th>fe_12_sum_all</th>\n",
       "      <th>fe_13_sum_all</th>\n",
       "      <th>fe_14_sum_all</th>\n",
       "      <th>fe_15_sum_all</th>\n",
       "      <th>fe_16_sum_all</th>\n",
       "      <th>fe_17_sum_all</th>\n",
       "      <th>fe_18_sum_all</th>\n",
       "      <th>fe_19_sum_all</th>\n",
       "      <th>fe_20_sum_all</th>\n",
       "      <th>fe_1</th>\n",
       "      <th>fe_2</th>\n",
       "      <th>fe_3</th>\n",
       "      <th>fe_4</th>\n",
       "      <th>fe_5</th>\n",
       "      <th>fe_6</th>\n",
       "      <th>fe_7</th>\n",
       "      <th>fe_8</th>\n",
       "      <th>fe_9</th>\n",
       "      <th>fe_10</th>\n",
       "      <th>fe_11</th>\n",
       "      <th>fe_12</th>\n",
       "      <th>fe_13</th>\n",
       "      <th>fe_14</th>\n",
       "      <th>fe_15</th>\n",
       "      <th>fe_16</th>\n",
       "      <th>fe_17</th>\n",
       "      <th>fe_18</th>\n",
       "      <th>fe_19</th>\n",
       "      <th>fe_20</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>42153.128906</td>\n",
       "      <td>1027.640015</td>\n",
       "      <td>341.0</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>154868.234375</td>\n",
       "      <td>242.750000</td>\n",
       "      <td>359.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>33209.269531</td>\n",
       "      <td>743.650024</td>\n",
       "      <td>209.0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14937.490234</td>\n",
       "      <td>3699.439941</td>\n",
       "      <td>165.0</td>\n",
       "      <td>7</td>\n",
       "      <td>15</td>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>90894.078125</td>\n",
       "      <td>49.520000</td>\n",
       "      <td>239.0</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Annual_Income  Outstanding_Debt  Credit_History_Age  Num_of_Loan  \\\n",
       "0   42153.128906       1027.640015               341.0            3   \n",
       "1  154868.234375        242.750000               359.0            0   \n",
       "2   33209.269531        743.650024               209.0            2   \n",
       "3   14937.490234       3699.439941               165.0            7   \n",
       "4   90894.078125         49.520000               239.0            4   \n",
       "\n",
       "   Num_of_Delayed_Payment  Delay_from_due_date  \\\n",
       "0                       9                   10   \n",
       "1                       3                   14   \n",
       "2                       4                   24   \n",
       "3                      15                   43   \n",
       "4                      13                    9   \n",
       "\n",
       "   Payment_Behaviour_High_spent_Small_value_payments  \\\n",
       "0                                                  1   \n",
       "1                                                  0   \n",
       "2                                                  0   \n",
       "3                                                  0   \n",
       "4                                                  0   \n",
       "\n",
       "   Payment_Behaviour_Low_spent_Large_value_payments  \\\n",
       "0                                                 0   \n",
       "1                                                 0   \n",
       "2                                                 0   \n",
       "3                                                 0   \n",
       "4                                                 0   \n",
       "\n",
       "   Payment_Behaviour_Low_spent_Medium_value_payments  \\\n",
       "0                                                  0   \n",
       "1                                                  0   \n",
       "2                                                  0   \n",
       "3                                                  1   \n",
       "4                                                  0   \n",
       "\n",
       "   Payment_Behaviour_Low_spent_Small_value_payments  \\\n",
       "0                                                 0   \n",
       "1                                                 0   \n",
       "2                                                 1   \n",
       "3                                                 0   \n",
       "4                                                 0   \n",
       "\n",
       "   Payment_Behaviour_High_spent_Medium_value_payments  \\\n",
       "0                                                  0    \n",
       "1                                                  0    \n",
       "2                                                  0    \n",
       "3                                                  0    \n",
       "4                                                  1    \n",
       "\n",
       "   Payment_Behaviour_High_spent_Large_value_payments  Credit_Mix_Standard  \\\n",
       "0                                                  0                    0   \n",
       "1                                                  0                    0   \n",
       "2                                                  0                    0   \n",
       "3                                                  0                    0   \n",
       "4                                                  0                    0   \n",
       "\n",
       "   Credit_Mix_Good  Credit_Mix_Bad  Type_of_Loan_Auto_Loan  \\\n",
       "0                1               0                       0   \n",
       "1                1               0                       0   \n",
       "2                0               0                       0   \n",
       "3                0               1                       0   \n",
       "4                1               0                       0   \n",
       "\n",
       "   Type_of_Loan_Credit_Builder_Loan  Type_of_Loan_Personal_Loan  \\\n",
       "0                                 0                           0   \n",
       "1                                 0                           0   \n",
       "2                                 0                           0   \n",
       "3                                 0                           0   \n",
       "4                                 0                           1   \n",
       "\n",
       "   Type_of_Loan_Home_Equity_Loan  Type_of_Loan_Mortgage_Loan  \\\n",
       "0                              0                           0   \n",
       "1                              0                           0   \n",
       "2                              0                           0   \n",
       "3                              1                           1   \n",
       "4                              0                           0   \n",
       "\n",
       "   Type_of_Loan_Student_Loan  Type_of_Loan_Debt_Consolidation_Loan  \\\n",
       "0                          0                                     0   \n",
       "1                          0                                     0   \n",
       "2                          0                                     1   \n",
       "3                          1                                     1   \n",
       "4                          1                                     0   \n",
       "\n",
       "   Type_of_Loan_Payday_Loan  is_occu_known  age_band_Unknown  age_band_18_24  \\\n",
       "0                         1              1                 0               0   \n",
       "1                         0              1                 0               0   \n",
       "2                         0              1                 0               0   \n",
       "3                         0              1                 1               0   \n",
       "4                         1              1                 0               0   \n",
       "\n",
       "   age_band_25_34  age_band_35_44  age_band_45_54  age_band_55  fe_1_sum_all  \\\n",
       "0               0               0               1            0             0   \n",
       "1               0               1               0            0             0   \n",
       "2               0               1               0            0             0   \n",
       "3               0               0               0            0             0   \n",
       "4               0               1               0            0             0   \n",
       "\n",
       "   fe_2_sum_all  fe_3_sum_all  fe_4_sum_all  fe_5_sum_all  fe_6_sum_all  \\\n",
       "0             0             0             0             0             0   \n",
       "1             0             0             0             0             0   \n",
       "2             0             0             0             0             0   \n",
       "3             0             0             0             0             0   \n",
       "4             0             0             0             0             0   \n",
       "\n",
       "   fe_7_sum_all  fe_8_sum_all  fe_9_sum_all  fe_10_sum_all  fe_11_sum_all  \\\n",
       "0             0             0             0              0              0   \n",
       "1             0             0             0              0              0   \n",
       "2             0             0             0              0              0   \n",
       "3             0             0             0              0              0   \n",
       "4             0             0             0              0              0   \n",
       "\n",
       "   fe_12_sum_all  fe_13_sum_all  fe_14_sum_all  fe_15_sum_all  fe_16_sum_all  \\\n",
       "0              0              0              0              0              0   \n",
       "1              0              0              0              0              0   \n",
       "2              0              0              0              0              0   \n",
       "3              0              0              0              0              0   \n",
       "4              0              0              0              0              0   \n",
       "\n",
       "   fe_17_sum_all  fe_18_sum_all  fe_19_sum_all  fe_20_sum_all  fe_1  fe_2  \\\n",
       "0              0              0              0              0     0     0   \n",
       "1              0              0              0              0     0     0   \n",
       "2              0              0              0              0     0     0   \n",
       "3              0              0              0              0     0     0   \n",
       "4              0              0              0              0     0     0   \n",
       "\n",
       "   fe_3  fe_4  fe_5  fe_6  fe_7  fe_8  fe_9  fe_10  fe_11  fe_12  fe_13  \\\n",
       "0     0     0     0     0     0     0     0      0      0      0      0   \n",
       "1     0     0     0     0     0     0     0      0      0      0      0   \n",
       "2     0     0     0     0     0     0     0      0      0      0      0   \n",
       "3     0     0     0     0     0     0     0      0      0      0      0   \n",
       "4     0     0     0     0     0     0     0      0      0      0      0   \n",
       "\n",
       "   fe_14  fe_15  fe_16  fe_17  fe_18  fe_19  fe_20  \n",
       "0      0      0      0      0      0      0      0  \n",
       "1      0      0      0      0      0      0      0  \n",
       "2      0      0      0      0      0      0      0  \n",
       "3      0      0      0      0      0      0      0  \n",
       "4      0      0      0      0      0      0      0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "66134fec-8c39-4534-ba33-7c54df519686",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ö†Ô∏è  No scaler found, using StandardScaler\n",
      "X_features 493\n"
     ]
    }
   ],
   "source": [
    "# Apply scaler if it exists\n",
    "if scaler is not None:\n",
    "    print(\"üîÑ Applying scaler transformation...\")\n",
    "    X_scaled = scaler.transform(X_features)\n",
    "    print(f\"‚úÖ Features scaled: {X_features.shape} -> {X_scaled.shape}\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  No scaler found, using StandardScaler\")\n",
    "    # --- Scaling ---\n",
    "    X_scaled = X_features\n",
    "\n",
    "print('X_features', X_features.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "57c10e52-1e21-493e-a872-6e303523b1b2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/site-packages/sklearn/utils/validation.py:2732: UserWarning: X has feature names, but LogisticRegression was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.00000000e+000, 1.71681326e-275, 1.00000000e+000, 0.00000000e+000,\n",
       "       2.28692236e-283, 7.93198390e-200, 0.00000000e+000, 1.25513932e-276,\n",
       "       5.96289160e-201, 5.62359156e-304, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 9.99972144e-001, 0.00000000e+000,\n",
       "       0.00000000e+000, 2.50726778e-069, 0.00000000e+000, 1.68110205e-063,\n",
       "       1.91593517e-060, 9.99999860e-001, 2.71116846e-137, 1.36993768e-076,\n",
       "       6.92609659e-063, 0.00000000e+000, 3.83152365e-010, 2.31672666e-023,\n",
       "       1.00000000e+000, 0.00000000e+000, 1.16097631e-203, 1.14559691e-071,\n",
       "       9.99999502e-001, 0.00000000e+000, 5.09166590e-126, 5.28449752e-023,\n",
       "       0.00000000e+000, 7.24890884e-151, 4.07639720e-306, 2.76562427e-164,\n",
       "       0.00000000e+000, 0.00000000e+000, 5.24073582e-075, 0.00000000e+000,\n",
       "       0.00000000e+000, 1.77718069e-069, 0.00000000e+000, 1.05665848e-230,\n",
       "       2.13920490e-299, 1.18591176e-192, 3.41591799e-130, 4.33416447e-266,\n",
       "       0.00000000e+000, 1.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 1.00000000e+000, 0.00000000e+000, 1.14732044e-280,\n",
       "       9.13594216e-001, 1.58011705e-248, 3.18954458e-238, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 1.72628500e-130, 4.10470289e-257,\n",
       "       1.99654543e-304, 1.07818403e-192, 0.00000000e+000, 6.07096777e-225,\n",
       "       0.00000000e+000, 1.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       1.52824946e-121, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       3.93602428e-283, 1.18329971e-033, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 2.89007790e-295, 3.57261873e-012,\n",
       "       0.00000000e+000, 1.80157946e-111, 1.00000000e+000, 0.00000000e+000,\n",
       "       1.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 5.01074621e-197,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 1.00000000e+000,\n",
       "       0.00000000e+000, 1.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 1.00000000e+000, 3.51862288e-062, 6.29545650e-074,\n",
       "       1.00000000e+000, 4.31509611e-170, 0.00000000e+000, 9.04330141e-001,\n",
       "       0.00000000e+000, 1.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 9.94639136e-151, 9.01381736e-169, 0.00000000e+000,\n",
       "       1.74162067e-240, 3.18318651e-233, 0.00000000e+000, 0.00000000e+000,\n",
       "       8.41612628e-109, 0.00000000e+000, 1.12464544e-062, 1.08271061e-017,\n",
       "       1.49253352e-221, 3.43332244e-104, 1.00000000e+000, 1.00000000e+000,\n",
       "       6.28075515e-140, 1.00000000e+000, 0.00000000e+000, 9.79849313e-001,\n",
       "       3.70053518e-123, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       1.00000000e+000, 0.00000000e+000, 1.32150736e-253, 0.00000000e+000,\n",
       "       1.64047068e-135, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 1.21741590e-242, 0.00000000e+000, 0.00000000e+000,\n",
       "       1.00000000e+000, 0.00000000e+000, 1.88922544e-189, 9.99985316e-001,\n",
       "       0.00000000e+000, 0.00000000e+000, 1.09332432e-033, 0.00000000e+000,\n",
       "       9.81473564e-072, 1.81643168e-290, 6.74454818e-101, 1.00000000e+000,\n",
       "       3.53782770e-039, 0.00000000e+000, 3.21099383e-194, 6.54795016e-079,\n",
       "       0.00000000e+000, 1.17659468e-018, 8.91005992e-238, 0.00000000e+000,\n",
       "       1.00000000e+000, 0.00000000e+000, 4.18912713e-255, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 9.92410210e-014,\n",
       "       3.47278455e-007, 6.59000185e-091, 1.00000000e+000, 1.02392134e-087,\n",
       "       7.77397898e-002, 1.92623446e-174, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 3.64716165e-289, 1.00000000e+000, 9.19371787e-295,\n",
       "       2.34647947e-078, 0.00000000e+000, 2.71602685e-004, 0.00000000e+000,\n",
       "       1.00000000e+000, 1.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 4.64455403e-083,\n",
       "       1.67028174e-306, 0.00000000e+000, 0.00000000e+000, 2.37358420e-103,\n",
       "       0.00000000e+000, 1.18360401e-264, 1.04613476e-053, 0.00000000e+000,\n",
       "       0.00000000e+000, 1.00000000e+000, 2.03686801e-053, 3.39668753e-101,\n",
       "       0.00000000e+000, 9.99997045e-001, 1.00000000e+000, 5.76893054e-135,\n",
       "       0.00000000e+000, 1.00000000e+000, 4.23240000e-240, 0.00000000e+000,\n",
       "       4.54783394e-005, 1.17507831e-090, 0.00000000e+000, 3.15773473e-081,\n",
       "       5.09539607e-236, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       1.19721696e-281, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 2.02455959e-193, 2.03156616e-231, 2.08944217e-159,\n",
       "       1.00000000e+000, 0.00000000e+000, 6.09340227e-133, 7.41793577e-302,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       1.83569221e-026, 0.00000000e+000, 2.67786303e-190, 1.00000000e+000,\n",
       "       3.20378609e-274, 0.00000000e+000, 1.19281271e-160, 3.01204370e-092,\n",
       "       2.10631758e-238, 0.00000000e+000, 4.71338028e-023, 8.04743793e-111,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       4.46228574e-179, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       1.00000000e+000, 7.16042057e-046, 0.00000000e+000, 9.99999938e-001,\n",
       "       0.00000000e+000, 1.00000000e+000, 0.00000000e+000, 1.00000000e+000,\n",
       "       1.43557375e-068, 0.00000000e+000, 1.00000000e+000, 1.00000000e+000,\n",
       "       4.48895375e-057, 0.00000000e+000, 1.66808930e-286, 0.00000000e+000,\n",
       "       8.97777027e-104, 0.00000000e+000, 7.11017012e-005, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 1.00000000e+000, 1.24535943e-114,\n",
       "       0.00000000e+000, 1.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 3.92245612e-244,\n",
       "       4.90264437e-163, 0.00000000e+000, 0.00000000e+000, 2.19647135e-185,\n",
       "       9.47406565e-050, 0.00000000e+000, 4.76187292e-209, 3.01679613e-296,\n",
       "       0.00000000e+000, 2.48633533e-251, 4.37922312e-112, 1.19129655e-121,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       6.69522665e-274, 5.22662828e-055, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 3.18311150e-176, 1.70848174e-236, 0.00000000e+000,\n",
       "       1.41099244e-028, 0.00000000e+000, 0.00000000e+000, 3.94776245e-090,\n",
       "       0.00000000e+000, 2.17486982e-002, 1.24466268e-048, 0.00000000e+000,\n",
       "       7.66930124e-256, 0.00000000e+000, 0.00000000e+000, 1.17648163e-113,\n",
       "       1.64001829e-079, 1.04975922e-150, 0.00000000e+000, 1.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 1.29707646e-146,\n",
       "       0.00000000e+000, 1.00000000e+000, 5.10176324e-272, 1.00000000e+000,\n",
       "       3.04313854e-257, 4.09459322e-162, 0.00000000e+000, 7.17422554e-065,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       8.83125236e-105, 1.80284975e-145, 2.21105318e-021, 0.00000000e+000,\n",
       "       0.00000000e+000, 1.67875486e-245, 0.00000000e+000, 0.00000000e+000,\n",
       "       1.00000000e+000, 0.00000000e+000, 1.00598550e-300, 1.38266910e-058,\n",
       "       3.71094111e-291, 3.25840359e-047, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 3.09807004e-060, 0.00000000e+000,\n",
       "       3.01257571e-084, 6.85507224e-219, 9.86703695e-046, 0.00000000e+000,\n",
       "       1.27063843e-297, 4.08526726e-139, 2.38586459e-304, 0.00000000e+000,\n",
       "       0.00000000e+000, 2.98013402e-077, 0.00000000e+000, 1.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 1.99356542e-156,\n",
       "       3.96238761e-178, 1.38135185e-051, 0.00000000e+000, 0.00000000e+000,\n",
       "       1.43332078e-197, 0.00000000e+000, 1.41674639e-265, 4.24579513e-195,\n",
       "       0.00000000e+000, 0.00000000e+000, 7.07731306e-080, 0.00000000e+000,\n",
       "       2.05914420e-083, 3.15962299e-099, 0.00000000e+000, 1.00000000e+000,\n",
       "       4.79144265e-020, 1.99005990e-143, 3.08064504e-179, 1.41565526e-103,\n",
       "       2.31238684e-272, 0.00000000e+000, 0.00000000e+000, 6.12475963e-187,\n",
       "       0.00000000e+000, 8.01689008e-064, 2.19940515e-234, 0.00000000e+000,\n",
       "       0.00000000e+000, 1.00000000e+000, 0.00000000e+000, 1.00000000e+000,\n",
       "       0.00000000e+000, 9.08423624e-013, 8.15943970e-050, 9.99707699e-001,\n",
       "       4.99889481e-091, 1.00000000e+000, 0.00000000e+000, 2.98241002e-109,\n",
       "       0.00000000e+000, 1.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 6.80296825e-185, 4.75847169e-144, 1.04179599e-056,\n",
       "       5.81707036e-192, 0.00000000e+000, 1.37321901e-283, 1.15243252e-300,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 3.81381971e-252,\n",
       "       0.00000000e+000, 1.18067681e-139, 0.00000000e+000, 2.36126386e-138,\n",
       "       1.00000000e+000, 0.00000000e+000, 2.73942844e-295, 0.00000000e+000,\n",
       "       2.32489044e-101, 0.00000000e+000, 2.25855130e-228, 4.60292256e-075,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 1.60225383e-083,\n",
       "       7.97293786e-195, 0.00000000e+000, 1.01015282e-160, 0.00000000e+000,\n",
       "       1.99561361e-099, 3.17924941e-223, 1.00000000e+000, 2.40676929e-086,\n",
       "       1.89444935e-090, 0.00000000e+000, 0.00000000e+000, 2.12958924e-054,\n",
       "       1.64804803e-021, 0.00000000e+000, 4.15052759e-127, 0.00000000e+000,\n",
       "       4.77097893e-084, 0.00000000e+000, 1.81577182e-231, 0.00000000e+000])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- model prediction inference ---\n",
    "# load model\n",
    "# model = model_artefact[\"model\"]\n",
    "\n",
    "# predict model\n",
    "y_inference = model.predict_proba(X_scaled)[:, 1]\n",
    "y_inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6c51daf3-cb14-43a2-8e5a-dbfc7bbadd3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare output\n",
    "y_inference_pdf = features_pdf[[\"Customer_ID\",\"snapshot_date\"]].copy()\n",
    "y_inference_pdf[\"model_name\"] = config[\"model_name\"]\n",
    "y_inference_pdf[\"model_predictions\"] = y_inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "31d5845b-0563-4b35-bb88-87883d185f8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Customer_ID</th>\n",
       "      <th>snapshot_date</th>\n",
       "      <th>model_name</th>\n",
       "      <th>model_predictions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CUS_0x1087</td>\n",
       "      <td>2024-09-01</td>\n",
       "      <td>LR</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CUS_0x1138</td>\n",
       "      <td>2024-09-01</td>\n",
       "      <td>LR</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CUS_0x121b</td>\n",
       "      <td>2024-09-01</td>\n",
       "      <td>LR</td>\n",
       "      <td>1.716813e-275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CUS_0x1232</td>\n",
       "      <td>2024-09-01</td>\n",
       "      <td>LR</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CUS_0x140e</td>\n",
       "      <td>2024-09-01</td>\n",
       "      <td>LR</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Customer_ID snapshot_date model_name  model_predictions\n",
       "0  CUS_0x1087    2024-09-01         LR       0.000000e+00\n",
       "1  CUS_0x1138    2024-09-01         LR       0.000000e+00\n",
       "2  CUS_0x121b    2024-09-01         LR      1.716813e-275\n",
       "3  CUS_0x1232    2024-09-01         LR       1.000000e+00\n",
       "4  CUS_0x140e    2024-09-01         LR       0.000000e+00"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_inference_pdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "173767d1-e130-457b-9318-324411605b9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/app/datamart/gold/model_predictions/LR/predictions_2024_09_01\n"
     ]
    }
   ],
   "source": [
    "# --- save model inference to datamart gold table ---\n",
    "# create gold datalake\n",
    "snapshot_date_path = config[\"snapshot_date_str\"].replace('-','_')\n",
    "prediction_directory = f\"/app/datamart/gold/model_predictions/{config[\"model_name\"]}/predictions_{snapshot_date_path}\"\n",
    "print(prediction_directory)\n",
    "\n",
    "if not os.path.exists(prediction_directory):\n",
    "    os.makedirs(prediction_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "93e4851c-fe3f-4d58-acf2-f557f488abf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = os.path.join(prediction_directory, f\"predictions_{snapshot_date_path}.csv\")\n",
    "y_inference_pdf.to_csv(filepath, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "07053b62-d072-4b6c-bf94-6b521fd93c60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "---completed job---\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# --- end spark session --- \n",
    "spark.stop()\n",
    "\n",
    "print('\\n\\n---completed job---\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8752e936-5515-4174-9ddc-c706946a74ec",
   "metadata": {},
   "source": [
    "## END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8d5600b1-4a05-4c36-87d0-82ee05c229ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available experiments:\n",
      "  ID: 6, Name: credit_model_LR_3, Lifecycle: active\n",
      "  ID: 5, Name: credit_model_XGB_2, Lifecycle: active\n",
      "  ID: 4, Name: credit_model_LR_2, Lifecycle: active\n",
      "  ID: 3, Name: loan_default_prediction, Lifecycle: active\n",
      "  ID: 0, Name: Default, Lifecycle: active\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "from mlflow.tracking import MlflowClient\n",
    "\n",
    "mlflow.set_tracking_uri(\"http://mlflow:5000\")\n",
    "client = MlflowClient()\n",
    "\n",
    "# List all experiments\n",
    "experiments = client.search_experiments()\n",
    "\n",
    "print(\"Available experiments:\")\n",
    "for exp in experiments:\n",
    "    print(f\"  ID: {exp.experiment_id}, Name: {exp.name}, Lifecycle: {exp.lifecycle_stage}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3cc4750c-fc14-476d-81e2-b78e4b34c144",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking run: 6e7db08463dc4107aab6c6f8f0d8b8ad\n",
      "\n",
      "‚ùå No artifacts found\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "from mlflow.tracking import MlflowClient\n",
    "\n",
    "mlflow.set_tracking_uri(\"http://mlflow:5000\")\n",
    "client = MlflowClient()\n",
    "\n",
    "# Check the latest run\n",
    "run_id = \"6e7db08463dc4107aab6c6f8f0d8b8ad\"\n",
    "\n",
    "print(f\"Checking run: {run_id}\\n\")\n",
    "\n",
    "# List artifacts\n",
    "artifacts = client.list_artifacts(run_id)\n",
    "\n",
    "if artifacts:\n",
    "    print(\"‚úÖ Artifacts found:\")\n",
    "    for artifact in artifacts:\n",
    "        print(f\"  - {artifact.path} (is_dir: {artifact.is_dir})\")\n",
    "        \n",
    "        # If it's a directory, list its contents\n",
    "        if artifact.is_dir:\n",
    "            sub_artifacts = client.list_artifacts(run_id, artifact.path)\n",
    "            for sub in sub_artifacts:\n",
    "                print(f\"    - {sub.path}\")\n",
    "    \n",
    "    # Try to load the model\n",
    "    print(\"\\n‚è±Ô∏è  Loading model...\")\n",
    "    model = mlflow.sklearn.load_model(f\"runs:/{run_id}/model\")\n",
    "    print(f\"‚úÖ Model loaded successfully! Type: {type(model).__name__}\")\n",
    "    \n",
    "    # Test prediction\n",
    "    import numpy as np\n",
    "    n_features = model.n_features_in_\n",
    "    dummy_data = np.random.rand(1, n_features)\n",
    "    prediction = model.predict(dummy_data)\n",
    "    \n",
    "    print(f\"\\n‚úÖ Test prediction successful!\")\n",
    "    print(f\"   Features: {n_features}\")\n",
    "    print(f\"   Prediction: {prediction}\")\n",
    "    \n",
    "else:\n",
    "    print(\"‚ùå No artifacts found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3fd9c6aa-4ab0-4d02-8ced-820e9979a82c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from registry...\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "No such file or directory: '/mlflow/mlruns/6/models/m-cb28067221ff4f0bba5a4948ebb01d33/artifacts/.'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mOSError\u001b[39m                                   Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m# Load the latest version from registry\u001b[39;00m\n\u001b[32m      7\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mLoading model from registry...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m model = \u001b[43mmlflow\u001b[49m\u001b[43m.\u001b[49m\u001b[43msklearn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodels:/credit_model_LR_3/latest\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m‚úÖ Model loaded! Version: 5\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     11\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m   Features expected: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel.n_features_in_\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/mlflow/sklearn/__init__.py:652\u001b[39m, in \u001b[36mload_model\u001b[39m\u001b[34m(model_uri, dst_path)\u001b[39m\n\u001b[32m    617\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mload_model\u001b[39m(model_uri, dst_path=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m    618\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    619\u001b[39m \u001b[33;03m    Load a scikit-learn model from a local file or a run.\u001b[39;00m\n\u001b[32m    620\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    650\u001b[39m \u001b[33;03m        predictions = sk_model.predict(pandas_df)\u001b[39;00m\n\u001b[32m    651\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m652\u001b[39m     local_model_path = \u001b[43m_download_artifact_from_uri\u001b[49m\u001b[43m(\u001b[49m\u001b[43martifact_uri\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel_uri\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdst_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    653\u001b[39m     flavor_conf = _get_flavor_configuration(model_path=local_model_path, flavor_name=FLAVOR_NAME)\n\u001b[32m    654\u001b[39m     _add_code_from_conf_to_system_path(local_model_path, flavor_conf)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/mlflow/tracking/artifact_utils.py:123\u001b[39m, in \u001b[36m_download_artifact_from_uri\u001b[39m\u001b[34m(artifact_uri, output_path, lineage_header_info, tracking_uri, registry_uri)\u001b[39m\n\u001b[32m    121\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    122\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(repo, ModelsArtifactRepository):\n\u001b[32m--> \u001b[39m\u001b[32m123\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrepo\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdownload_artifacts\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    124\u001b[39m \u001b[43m            \u001b[49m\u001b[43martifact_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43martifact_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    125\u001b[39m \u001b[43m            \u001b[49m\u001b[43mdst_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    126\u001b[39m \u001b[43m            \u001b[49m\u001b[43mlineage_header_info\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlineage_header_info\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    127\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    128\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m repo.download_artifacts(artifact_path=artifact_path, dst_path=output_path)\n\u001b[32m    129\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/mlflow/store/artifact/models_artifact_repo.py:249\u001b[39m, in \u001b[36mModelsArtifactRepository.download_artifacts\u001b[39m\u001b[34m(self, artifact_path, dst_path, lineage_header_info)\u001b[39m\n\u001b[32m    245\u001b[39m     model_path = \u001b[38;5;28mself\u001b[39m.repo.download_artifacts(\n\u001b[32m    246\u001b[39m         artifact_path, dst_path, lineage_header_info=lineage_header_info\n\u001b[32m    247\u001b[39m     )\n\u001b[32m    248\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m249\u001b[39m     model_path = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrepo\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdownload_artifacts\u001b[49m\u001b[43m(\u001b[49m\u001b[43martifact_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdst_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    250\u001b[39m \u001b[38;5;66;03m# NB: only add the registered model metadata iff the artifact path is at the root model\u001b[39;00m\n\u001b[32m    251\u001b[39m \u001b[38;5;66;03m# directory. For individual files or subdirectories within the model directory, do not\u001b[39;00m\n\u001b[32m    252\u001b[39m \u001b[38;5;66;03m# create the metadata file.\u001b[39;00m\n\u001b[32m    253\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m os.path.isdir(model_path) \u001b[38;5;129;01mand\u001b[39;00m MLMODEL_FILE_NAME \u001b[38;5;129;01min\u001b[39;00m os.listdir(model_path):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/mlflow/store/artifact/local_artifact_repo.py:94\u001b[39m, in \u001b[36mLocalArtifactRepository.download_artifacts\u001b[39m\u001b[34m(self, artifact_path, dst_path)\u001b[39m\n\u001b[32m     92\u001b[39m local_artifact_path = os.path.join(\u001b[38;5;28mself\u001b[39m.artifact_dir, os.path.normpath(artifact_path))\n\u001b[32m     93\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os.path.exists(local_artifact_path):\n\u001b[32m---> \u001b[39m\u001b[32m94\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mNo such file or directory: \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlocal_artifact_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     95\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m os.path.abspath(local_artifact_path)\n",
      "\u001b[31mOSError\u001b[39m: No such file or directory: '/mlflow/mlruns/6/models/m-cb28067221ff4f0bba5a4948ebb01d33/artifacts/.'"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "import numpy as np\n",
    "\n",
    "mlflow.set_tracking_uri(\"http://mlflow:5000\")\n",
    "\n",
    "# Load the latest version from registry\n",
    "print(\"Loading model from registry...\")\n",
    "model = mlflow.sklearn.load_model(\"models:/credit_model_LR_3/latest\")\n",
    "\n",
    "print(f\"‚úÖ Model loaded! Version: 5\")\n",
    "print(f\"   Features expected: {model.n_features_in_}\")\n",
    "\n",
    "\n",
    "# Test prediction\n",
    "dummy_data = np.random.rand(1, model.n_features_in_)\n",
    "prediction = model.predict(dummy_data)\n",
    "prediction_proba = model.predict_proba(dummy_data)\n",
    "\n",
    "print(f\"\\n‚úÖ Prediction test passed!\")\n",
    "print(f\"   Prediction: {prediction}\")\n",
    "print(f\"   Probability: {prediction_proba}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
